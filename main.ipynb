{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff643e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install qdrant-client fastapi uvicorn[standard] sentence-transformers transformers nest_asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, PointStruct\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from fastapi import FastAPI, Request\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import uuid\n",
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a574131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "COLLECTION_NAME = \"rag_docs\"\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6edeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_documents(documents):\n",
    "    vectors = embedding_model.encode(documents).tolist()\n",
    "    points = [\n",
    "        PointStruct(id=str(uuid.uuid4()), vector=vec, payload={\"text\": doc})\n",
    "        for vec, doc in zip(vectors, documents)\n",
    "    ]\n",
    "    client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "\n",
    "documents = [\n",
    "    \"Indonesia adalah negara kepulauan terbesar di dunia.\",\n",
    "    \"Python adalah bahasa pemrograman populer untuk data science.\",\n",
    "    \"Qdrant adalah vektor database untuk pencarian semantik.\"\n",
    "]\n",
    "add_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "def rag_answer(question: str):\n",
    "    question_vec = embedding_model.encode([question])[0].tolist()\n",
    "    hits = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_vector=question_vec,\n",
    "        limit=3\n",
    "    )\n",
    "    context = \"\\n\".join([hit.payload[\"text\"] for hit in hits])\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    output = llm(prompt, max_new_tokens=100, do_sample=True)[0][\"generated_text\"]\n",
    "    return output.split(\"Answer:\")[-1].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee7cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/ask\")\n",
    "async def ask(request: Request):\n",
    "    body = await request.json()\n",
    "    question = body.get(\"question\", \"\")\n",
    "    answer = rag_answer(question)\n",
    "    return {\"question\": question, \"answer\": answer}\n",
    "\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
